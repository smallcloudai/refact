cloud_name: HuggingFace API

completion_endpoint: "https://api-inference.huggingface.co/models/$MODEL"
completion_endpoint_style: "hf"
completion_model: bigcode/starcoder2-3b
completion_apikey: "$HF_TOKEN"

chat_endpoint: "https://api-inference.huggingface.co/models/$MODEL"
chat_endpoint_style: "hf"
chat_apikey: "$HF_TOKEN"
chat_model: meta-llama/Llama-2-70b-chat-hf

tokenizer_rewrite_path:   # because you need to agree to licensing agreement in the official repo to even download a tokenizer
  meta-llama/Llama-2-70b-chat-hf: TheBloke/Llama-2-70B-fp16

embedding_endpoint: "https://api-inference.huggingface.co/pipeline/feature-extraction/$MODEL"
embedding_endpoint_style: "hf"
embedding_apikey: "$HF_TOKEN"
embedding_model: thenlper/gte-base
embedding_size: 768
#embedding_batch: 64

import { CapsResponse } from "../services/refact";

export const STUB_CAPS_RESPONSE: CapsResponse = {
  cloud_name: "Refact",
  endpoint_style: "openai",
  code_completion_n_ctx: 4000,
  tokenizer_rewrite_path: {
    "o1-mini": "Xenova/gpt-4o",
    "gpt-4-turbo-2024-04-09": "Xenova/gpt-4",
    "Refact/1.6B": "smallcloudai/Refact-1_6B-fim",
    "claude-3-5-sonnet-20240620": "Xenova/claude-tokenizer",
    "gpt-4-turbo": "Xenova/gpt-4",
    "qwen2.5/coder/1.5b/base": "Qwen/Qwen2.5-Coder-1.5B",
    "text-embedding-3-small": "Xenova/text-embedding-ada-002",
    "gpt-4": "Xenova/gpt-4",
    "claude-3-5-sonnet-20241022": "Xenova/claude-tokenizer",
    "claude-3-5-sonnet": "Xenova/claude-tokenizer",
    "gpt-3.5-turbo-0125": "Xenova/gpt-3.5-turbo-16k",
    "gpt-3.5-turbo": "Xenova/gpt-3.5-turbo-16k",
    "gpt-4o-mini-2024-07-18": "Xenova/gpt-4o",
    "gpt-4o-2024-08-06": "Xenova/gpt-4o",
    "gpt-3.5-turbo-1106": "Xenova/gpt-3.5-turbo-16k",
    "openai/gpt-4-turbo": "Xenova/gpt-4",
    "gpt-4o-2024-05-13": "Xenova/gpt-4o",
    "openai/gpt-4o-mini": "Xenova/gpt-4o",
    "openai/gpt-4o": "Xenova/gpt-4o",
    "gpt-4o-mini": "Xenova/gpt-4o",
    "openai/gpt-4": "Xenova/gpt-4",
    "gpt-4o": "Xenova/gpt-4o",
    "openai/gpt-3.5-turbo": "Xenova/gpt-3.5-turbo-16k",
    "cerebras-llama3.1-8b": "Xenova/Meta-Llama-3.1-Tokenizer",
    "groq-llama-3.1-8b": "Xenova/Meta-Llama-3.1-Tokenizer",
    "starcoder2/3b": "bigcode/starcoder2-3b",
  },
  telemetry_basic_dest: "https://www.smallcloud.ai/v1/telemetry-basic",
  telemetry_basic_retrieve_my_own:
    "https://staging.smallcloud.ai/v1/telemetry-retrieve-my-own-stats",
  tokenizer_path_template:
    "https://huggingface.co/$MODEL/resolve/main/tokenizer.json",
  endpoint_chat_passthrough:
    "https://inference.smallcloud.ai/v1/chat/completions",
  endpoint_template: "https://inference.smallcloud.ai/v1/completions",
  completion_models: {
    "Refact/smallcloudai/Refact-1_6B-fim": {
      n_ctx: 4000,
      name: "smallcloudai/Refact-1_6B-fim",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/Refact/1.6B": {
      n_ctx: 4000,
      name: "Refact/1.6B",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/starcoder2/3b": {
      n_ctx: 4000,
      name: "starcoder2/3b",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/qwen2.5/coder/1.5b/base": {
      n_ctx: 4000,
      name: "qwen2.5/coder/1.5b/base",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gpt-4o": {
      n_ctx: 4000,
      name: "gpt-4o",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gpt-4o-mini": {
      n_ctx: 4000,
      name: "gpt-4o-mini",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/claude-3-5-sonnet": {
      n_ctx: 4000,
      name: "claude-3-5-sonnet",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/claude-3-5-haiku": {
      n_ctx: 4000,
      name: "claude-3-5-haiku",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/claude-3-7-sonnet": {
      n_ctx: 4000,
      name: "claude-3-7-sonnet",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/groq-llama-3.1-8b": {
      n_ctx: 4000,
      name: "groq-llama-3.1-8b",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/groq-llama-3.1-70b": {
      n_ctx: 4000,
      name: "groq-llama-3.1-70b",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gemini-2.0-flash-exp": {
      n_ctx: 4000,
      name: "gemini-2.0-flash-exp",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gemini-1.5-flash": {
      n_ctx: 4000,
      name: "gemini-1.5-flash",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gemini-1.5-flash-8b": {
      n_ctx: 4000,
      name: "gemini-1.5-flash-8b",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/gemini-1.5-pro": {
      n_ctx: 4000,
      name: "gemini-1.5-pro",
      enabled: true,
      type: "completion",
      model_family: null,
    },
    "Refact/gemini-2.0-exp-advanced": {
      n_ctx: 4000,
      name: "gemini-2.0-exp-advanced",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/grok-2": {
      n_ctx: 4000,
      name: "grok-2",
      enabled: true,
      model_family: null,
      type: "completion",
    },
    "Refact/deepseek-chat": {
      n_ctx: 4000,
      name: "deepseek-chat",
      type: "completion",
      enabled: true,
      model_family: null,
    },
  },
  chat_models: {
    "Refact/gpt-4o": {
      n_ctx: 128000,
      name: "gpt-4o",
      id: "Refact/gpt-4o",
      type: "chat",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gpt-4o-mini": {
      n_ctx: 128000,
      name: "gpt-4o-mini",
      id: "Refact/gpt-4o-mini",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      type: "chat",
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/o1": {
      n_ctx: 200000,
      name: "o1",
      id: "Refact/o1",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      type: "chat",
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: "openai",
      supports_boost_reasoning: true,
      default_temperature: null,
    },
    "Refact/o1-mini": {
      n_ctx: 128000,
      name: "o1-mini",
      id: "Refact/o1-mini",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      type: "chat",
      supports_agent: false,
      supports_reasoning: "openai",
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/o3-mini": {
      n_ctx: 200000,
      name: "o3-mini",
      id: "Refact/o3-mini",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      type: "chat",
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: "openai",
      supports_boost_reasoning: true,
      default_temperature: null,
    },
    "Refact/claude-3-5-sonnet": {
      n_ctx: 200000,
      name: "claude-3-5-sonnet",
      id: "Refact/claude-3-5-sonnet",
      enabled: true,
      type: "chat",
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/claude-3-5-haiku": {
      type: "chat",
      n_ctx: 200000,
      name: "claude-3-5-haiku",
      id: "Refact/claude-3-5-haiku",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/claude-3-7-sonnet": {
      type: "chat",
      n_ctx: 200000,
      name: "claude-3-7-sonnet",
      id: "Refact/claude-3-7-sonnet",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: true,
      supports_agent: true,
      supports_reasoning: "anthropic",
      supports_boost_reasoning: true,
      default_temperature: null,
    },
    "Refact/groq-llama-3.1-8b": {
      type: "chat",
      n_ctx: 128000,
      name: "groq-llama-3.1-8b",
      id: "Refact/groq-llama-3.1-8b",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/groq-llama-3.1-70b": {
      type: "chat",
      n_ctx: 128000,
      name: "groq-llama-3.1-70b",
      id: "Refact/groq-llama-3.1-70b",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gemini-2.0-flash-exp": {
      type: "chat",
      n_ctx: 1000000,
      name: "gemini-2.0-flash-exp",
      id: "Refact/gemini-2.0-flash-exp",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gemini-1.5-flash": {
      type: "chat",
      n_ctx: 1000000,
      name: "gemini-1.5-flash",
      id: "Refact/gemini-1.5-flash",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gemini-1.5-flash-8b": {
      type: "chat",
      n_ctx: 1000000,
      name: "gemini-1.5-flash-8b",
      id: "Refact/gemini-1.5-flash-8b",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gemini-1.5-pro": {
      type: "chat",
      n_ctx: 2000000,
      name: "gemini-1.5-pro",
      id: "Refact/gemini-1.5-pro",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/gemini-2.0-exp-advanced": {
      type: "chat",
      n_ctx: 1000000,
      name: "gemini-2.0-exp-advanced",
      id: "Refact/gemini-2.0-exp-advanced",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: true,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/grok-2": {
      type: "chat",
      n_ctx: 128000,
      name: "grok-2",
      id: "Refact/grok-2",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/deepseek-chat": {
      type: "chat",
      n_ctx: 64000,
      name: "deepseek-chat",
      id: "Refact/deepseek-chat",
      enabled: true,
      tokenizer: "fake",
      supports_tools: true,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: true,
      supports_reasoning: null,
      supports_boost_reasoning: false,
      default_temperature: null,
    },
    "Refact/deepseek-reasoner": {
      type: "chat",
      n_ctx: 64000,
      name: "deepseek-reasoner",
      id: "Refact/deepseek-reasoner",
      enabled: true,
      tokenizer: "fake",
      supports_tools: false,
      supports_multimodality: false,
      supports_clicks: false,
      supports_agent: false,
      supports_reasoning: "deepseek",
      supports_boost_reasoning: false,
      default_temperature: 0.6,
    },
  },
  embedding_model: {
    type: "embedding",
    n_ctx: 512,
    enabled: true,
    tokenizer: "fake",
    embedding_size: 1536,
    name: "thenlper/gte-base",
    id: "Refact/thenlper/gte-base",
    rejection_threshold: 0.25,
    embedding_batch: 64,
  },
  running_models: [
    "smallcloudai/Refact-1_6B-fim",
    "Refact/1.6B",
    "thenlper/gte-base",
    "starcoder2/3b",
    "qwen2.5/coder/1.5b/base",
    "gpt-3.5-turbo",
    "gpt-4-turbo",
    "gpt-4o",
    "gpt-4o-mini",
    "claude-3-5-sonnet",
    "groq-llama-3.1-8b",
    "groq-llama-3.1-70b",
  ],
  completion_default_model: "Refact/1.6B",
  chat_default_model: "gpt-4o",
  chat_thinking_model: "",
  chat_light_model: "",
  caps_version: 0,
  code_chat_default_system_prompt: "default",
  support_metadata: true,
  metadata: {
    pricing: {
      "gpt-3.5-turbo": {
        prompt: 0.5,
        generated: 1.5,
      },
      "gpt-4-turbo": {
        prompt: 10.0,
        generated: 30.0,
      },
      "gpt-4o": {
        prompt: 2.5,
        generated: 10.0,
        cache_read: 1.25,
      },
      "gpt-4o-mini": {
        prompt: 0.15,
        generated: 0.6,
        cache_read: 0.075,
      },
      "chatgpt-4o": {
        prompt: 5.0,
        generated: 15.0,
      },
      o1: {
        prompt: 15.0,
        generated: 60.0,
        cache_read: 7.5,
      },
      "o1-mini": {
        prompt: 1.1,
        generated: 4.4,
        cache_read: 0.55,
      },
      "o3-mini": {
        prompt: 1.1,
        generated: 4.4,
        cache_read: 0.55,
      },
      o3: {
        prompt: 10.0,
        generated: 40.0,
        cache_read: 2.5,
      },
      "o4-mini": {
        prompt: 1.1,
        generated: 4.4,
        cache_read: 0.275,
      },
      "gpt-4.1": {
        prompt: 2.0,
        generated: 8.0,
        cache_read: 0.5,
      },
      "gpt-4.1-mini": {
        prompt: 0.4,
        generated: 1.6,
        cache_read: 0.1,
      },
      "gpt-4.1-nano": {
        prompt: 0.1,
        generated: 0.4,
        cache_read: 0.025,
      },
      "claude-3-5-sonnet": {
        prompt: 3.0,
        generated: 15.0,
        cache_creation: 3.75,
        cache_read: 0.3,
      },
      "claude-3-5-haiku": {
        prompt: 0.8,
        generated: 4.0,
        cache_creation: 1.0,
        cache_read: 0.08,
      },
      "claude-3-7-sonnet": {
        prompt: 3.0,
        generated: 15.0,
        cache_creation: 3.75,
        cache_read: 0.3,
      },
      "groq-llama-3.1-8b": {
        prompt: 0.05,
        generated: 0.08,
      },
      "groq-llama-3.1-70b": {
        prompt: 0.59,
        generated: 0.79,
      },
      "gemini-2.0-flash-exp": {
        prompt: 0.075,
        generated: 0.3,
      },
      "gemini-1.5-flash": {
        prompt: 0.075,
        generated: 0.3,
      },
      "gemini-1.5-flash-8b": {
        prompt: 0.0375,
        generated: 0.15,
      },
      "gemini-1.5-pro": {
        prompt: 1.25,
        generated: 5.0,
      },
      "gemini-2.0-exp-advanced": {
        prompt: 1.25,
        generated: 5.0,
      },
      "gemini-2.5-pro": {
        prompt: 1.25,
        generated: 10.0,
      },
      "grok-2": {
        prompt: 5.0,
        generated: 15.0,
      },
      "deepseek-chat": {
        prompt: 0.27,
        generated: 1.1,
      },
      "deepseek-reasoner": {
        prompt: 0.55,
        generated: 2.19,
      },
    },
  },
  customization: "",
};

export const EMPTY_CAPS_RESPONSE: CapsResponse = {
  support_metadata: false,
  caps_version: 0,
  cloud_name: "",
  chat_default_model: "",
  code_chat_default_system_prompt: "",
  chat_models: {},
  completion_default_model: "",
  completion_models: {},
  code_completion_n_ctx: 0,
  endpoint_chat_passthrough: "",
  endpoint_style: "",
  endpoint_template: "",
  running_models: [],
  telemetry_basic_dest: "",
  tokenizer_path_template: "",
  customization: "",
  tokenizer_rewrite_path: {},
  metadata: { pricing: {} },
  chat_light_model: "",
  chat_thinking_model: "",
  telemetry_basic_retrieve_my_own: "",
};
